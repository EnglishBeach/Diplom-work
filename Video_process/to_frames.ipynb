{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.widgets import  Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = \"Videos/Start1.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = CAP.get(cv2.CAP_PROP_FPS)\n",
    "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Preprocess\n",
    "def image_process(img):\n",
    "    return img\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=0, right=1, top=1, hspace=0, bottom=0.2)\n",
    "# del ax.xaxis, ax.yaxis\n",
    "\n",
    "axfreq = fig.add_axes([0.2, 0.1, 0.6, 0.05])\n",
    "TIME_slider = Slider(\n",
    "    ax=axfreq,\n",
    "    label='Time',\n",
    "    valmin=0,\n",
    "    valmax=LENTH,\n",
    "    valinit=0,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "def update(val):\n",
    "    time = TIME_slider.val\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, int(FPS*time))\n",
    "    _, frame = CAP.read()\n",
    "\n",
    "    \n",
    "    plot.set_data(frame)\n",
    "    plot.autoscale()\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "TIME_slider.on_changed(update)\n",
    "\n",
    "\n",
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, frame = CAP.read()\n",
    "plot = ax.imshow(frame,cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"Videos/Full_font2.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving\n",
    "# fps =int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# diap = tqdm(iterable=range(0,fps*40,fps))\n",
    "# for i in diap:\n",
    "#     cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         cv2.imwrite(f\"Images/frame{int(i/fps)}.jpg\",frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(image, thresh):\n",
    "    frame_2color = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh, frame_bw = cv2.threshold(frame_2color, thresh, 255,\n",
    "                                     cv2.THRESH_BINARY)\n",
    "    return tes.image_to_string(frame_bw), frame_bw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "THRESH = 147\n",
    "\n",
    "cap = cv2.VideoCapture(\"Videos/Full_font2.avi\")\n",
    "pdf_file = PdfPages('Full_font2.pdf')\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "diap = tqdm(iterable=range(0, fps * 40, fps))\n",
    "\n",
    "for i in diap:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    ready, frame = cap.read()\n",
    "    text, frame_treated = recognize(frame, thresh=THRESH)\n",
    "    text = text.replace('\\n', '')\n",
    "    text = f\"t={i/fps: .1f}|{text}\"\n",
    "    if ready:\n",
    "        fig, (ax_row, ax_treated) = plt.subplots(ncols=2)\n",
    "\n",
    "        ax_row.imshow(frame)\n",
    "        ax_treated.imshow(frame_treated)\n",
    "        ax_row.text(0, 0, text, fontsize=15)\n",
    "\n",
    "        fig.savefig(pdf_file, format='pdf')\n",
    "        plt.close()\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One frame tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture()\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ready, frame = cap.read()\n",
    "frame = frame\n",
    "# [200:280]\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = frame[:, :, :]\n",
    "frame2 = (frame2 + 1) % 256\n",
    "plt.imshow(frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reader.readtext(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test easy ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"Videos/Start5.avi\")\n",
    "pdf_file = PdfPages('Easy_Start5_test.pdf')\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / fps)\n",
    "\n",
    "diap = tqdm(iterable=range(fps * 87, fps * 89, int(fps / 5)))\n",
    "try:\n",
    "    for i in diap:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ready, frame = cap.read()\n",
    "        frame = frame[100:142]\n",
    "        result = reader.readtext(frame)\n",
    "\n",
    "        if ready:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            ax.imshow(frame)\n",
    "            text_result = ' -- '.join([\n",
    "                f'{value}({confidence*100:.0f})'\n",
    "                for _, value, confidence in result\n",
    "            ])\n",
    "            ax.set_title(f'T= {round(i/fps,1)}  R= {text_result}')\n",
    "\n",
    "            fig.savefig(pdf_file, format='pdf')\n",
    "            plt.close()\n",
    "except:\n",
    "    print('Error has been detected')\n",
    "finally:\n",
    "    pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([value for _, value, confidence in result])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from skimage import data\n",
    "\n",
    "img = data.chelsea()\n",
    "fig = px.imshow(img)\n",
    "# fig.add_annotation(\n",
    "#     x=0.5,\n",
    "#     y=0.9,\n",
    "#     text=\"Drag and draw annotations\",\n",
    "#     xref=\"paper\",\n",
    "#     yref=\"paper\",\n",
    "#     showarrow=False,\n",
    "#     font_size=20, font_color='cyan')\n",
    "# Shape defined programatically\n",
    "# fig.add_shape(\n",
    "#     type='rect',\n",
    "#     x0=230, x1=290, y0=230, y1=280,\n",
    "#     xref='x', yref='y',\n",
    "#     line_color='cyan'\n",
    "# )\n",
    "# Define dragmode, newshape parameters, amd add modebar buttons\n",
    "\n",
    "\n",
    "# fig.update_layout(dragmode='drawrect', newshape=dict(line_color='cyan'))\n",
    "\n",
    "fig.show(config={'modeBarButtonsToAdd': ['drawrect', 'eraseshape']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.colors import n_colors\n",
    "\n",
    "# Загрузка изображения\n",
    "img = go.Image(z=frame)\n",
    "\n",
    "# Определение области, которую нужно обрезать\n",
    "clip_path = go.Scatter(\n",
    "    x=[100, 300, 300, 100],\n",
    "    y=[100, 100, 300, 300],\n",
    "    fill='toself'\n",
    ")\n",
    "\n",
    "# Определение фигуры с изображением и обрезанной областью\n",
    "fig = go.Figure(data=[img])\n",
    "fig.update_layout(width=600, height=600)\n",
    "fig.update_layout(images=[dict(\n",
    "    data=img,\n",
    "    xref='x',\n",
    "    yref='y',\n",
    "    x=clip_path.x[0],\n",
    "    y=clip_path.y[0],\n",
    "    sizex=clip_path.x[2] - clip_path.x[0],\n",
    "    sizey=clip_path.y[2] - clip_path.y[0],\n",
    "    sizing='stretch',\n",
    "    opacity=1.0,\n",
    "    layer='below',\n",
    "    # sourcetype='image',\n",
    "    # sourceopacity=1.0,\n",
    "    # clippath=f\"test.jpg\",\n",
    "    # cliponaxis=False\n",
    ")])\n",
    "\n",
    "# Определение цветов для обрезки\n",
    "colors = n_colors('rgb(255, 0, 0)', 'rgb(0, 0, 255)', 10)\n",
    "\n",
    "# Определение состояния для обрезки\n",
    "state = {'color': 0}\n",
    "\n",
    "# Обработчик событий для кликов мыши\n",
    "def handle_click(trace, points, state):\n",
    "    if len(points.point_inds) > 0:\n",
    "        state['color'] = (state['color'] + 1) % len(colors)\n",
    "        color = colors[state['color']]\n",
    "        fig.update_traces(patch=dict(fillcolor=color))\n",
    "\n",
    "# Добавление обработчика событий для кликов мыши\n",
    "fig.data[0].on_click(lambda trace, points, state: handle_click(trace, points, state))\n",
    "\n",
    "# Отображение фигуры\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zVid_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5946b119aa0342abd5386a0c5beb8d13f5e9da65c541c34995194e58e5a123e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
