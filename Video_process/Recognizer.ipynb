{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importing...\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.widgets import  Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = None\n",
    "# \"Videos/Start1.avi\"\n",
    "if VIDEO_PATH is None:\n",
    "    input_path =''\n",
    "    while input_path == '':\n",
    "        input_path = input(\n",
    "            f\"Input video path: \")\n",
    "    VIDEO_PATH = input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
    "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "def image_process(frame, blur=1):\n",
    "    frame = cv2.blur(frame, (BLUR, BLUR))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.bitwise_not(frame)\n",
    "    return frame\n",
    "\n",
    "\n",
    "BLUR = 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "fig.subplots_adjust(left=0.25, right=1, bottom=0.25, top=1, hspace=0, wspace=0)\n",
    "\n",
    "PLOT = ax.imshow(image_process(START_FRAME), cmap='binary')\n",
    "\n",
    "ax_time_slider = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "TIME_slider = Slider(\n",
    "    ax=ax_time_slider,\n",
    "    label='Time',\n",
    "    valmin=0,\n",
    "    valmax=LENTH,\n",
    "    valinit=0,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "ax_blur_slider = fig.add_axes([0.1, 0.25, 0.03, 0.6])\n",
    "BLUR_slider = Slider(\n",
    "    ax=ax_blur_slider,\n",
    "    orientation='vertical',\n",
    "    label='Blur',\n",
    "    valmin=BLUR,\n",
    "    valmax=20,\n",
    "    valinit=1,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    time = TIME_slider.val\n",
    "    global BLUR\n",
    "    BLUR = BLUR_slider.val\n",
    "\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, int(FPS * time))\n",
    "    _, frame = CAP.read()\n",
    "    frame = image_process(frame, blur=BLUR)\n",
    "\n",
    "    PLOT.set_data(frame)\n",
    "    PLOT.autoscale()\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "TIME_slider.on_changed(update)\n",
    "BLUR_slider.on_changed(update)\n",
    "print('Configurate image processing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input('Continue to selection?')\n",
    "print(f'Blur value= {BLUR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection\n",
    "def strict(image, x, y, w, h):\n",
    "    return image[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "SLICE_CORDS = []\n",
    "values_to_recognize = int(input('Values to recognize: '))\n",
    "\n",
    "for i in range(values_to_recognize):\n",
    "    roi_frame = image_process(START_FRAME, blur=BLUR)\n",
    "    roi_frame = cv2.bitwise_not(roi_frame)\n",
    "    current_slice = cv2.selectROI(\n",
    "        f'Select {len(SLICE_CORDS)+1}',\n",
    "        roi_frame,\n",
    "        fromCenter=False,\n",
    "        showCrosshair=True,\n",
    "    )\n",
    "    SLICE_CORDS.append(current_slice)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=values_to_recognize)\n",
    "if not isinstance(axes, np.ndarray): axes = [axes]\n",
    "fig.set_size_inches(3, 1 * values_to_recognize)\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0.0, top=1, hspace=0, wspace=0)\n",
    "start_slices = [\n",
    "    strict(image_process(START_FRAME, blur=BLUR), *params)\n",
    "    for params in SLICE_CORDS\n",
    "]\n",
    "for i in range(values_to_recognize):\n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].imshow(start_slices[i], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize\n",
    "def correct(values):\n",
    "    return values\n",
    "\n",
    "\n",
    "print('Starting recognizer...')\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "input_fps = input('Input number of frames per second: ')\n",
    "try:\n",
    "    read_fps = int(input_fps)\n",
    "except:\n",
    "    read_fps = 1\n",
    "\n",
    "print('Recognizing:')\n",
    "diap = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
    "\n",
    "data = []\n",
    "for i_frame in diap:\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "    _, frame = CAP.read()\n",
    "    i_text = []\n",
    "    for select_window in SLICE_CORDS:\n",
    "        selection = strict(frame, *select_window)\n",
    "        selection = image_process(selection, blur=BLUR)\n",
    "        values = [\n",
    "            (value, round(confidence,3)) for _, value, confidence\n",
    "            in reader.readtext(selection)\n",
    "            ] #yapf:disable\n",
    "\n",
    "        i_text.append(values)\n",
    "\n",
    "    data.append(i_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zVid_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5946b119aa0342abd5386a0c5beb8d13f5e9da65c541c34995194e58e5a123e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
